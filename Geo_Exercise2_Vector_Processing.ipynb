{"cells":[{"cell_type":"markdown","source":["# GeoJSON ファイルのロードと計算処理の分散実行\n\nこのエクササイズでは、**行ごとにポリゴン情報が含まれる** [GeoJSONSeq](https://gdal.org/drivers/vector/geojsonseq.html) ファイルを Spark でロードし、各ワーカー上で分散処理を行います。\n\nSpark SQL は自動的にJSONデータセットのスキーマを推測しデータフレームとしてロードすることができます。この変換は、JSONファイル上の `SparkSession.read.json` を使って行うことができます。\n\n`spark.read.json` が求めるファイルは一般的な JSON ファイルではないことに注意してください。各行は別個の自己内包の有効な JSON オブジェクトでなければなりません。これは [JSON Lines](https://jsonlines.org/) や [Newline-Delimited JSON](http://ndjson.org/) とも呼ばれます。\n\nhttp://mogile.web.fc2.com/spark/sql-data-sources-json.html"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"76bfc641-9f6d-4ce4-a54e-99cee609d4ff","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## JSON ファイルのロード"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f87b763e-a4b1-4f12-9d4a-8e0a7d4b5e44","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%%time\n\ndf = spark.read.json(\"/mnt/testblob/geojson/niigata_cropfiled_geojsonl.json\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02fa59e6-5401-4f7b-bc26-c896f49b77c4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## データの取得\nPySparkでは、アクションを使用してDataFrame `show()` の先頭/最初の N (5,10,100 ..) 行を取得し、それらをコンソールまたはログに表示できます。行のリストとしての先頭と最後の n 行 (Scala の場合は Array[Row])。Spark アクションは Spark Driver に結果を取得するため、大きなデータセットを抽出するときは十分に注意する必要があります。\n\nhttps://sparkbyexamples.com/spark/show-top-n-rows-in-spark-pyspark/"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bb87a725-cfa7-422c-9df7-bf815108c76b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["display(df.take(5))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"50837d4e-818d-4e88-9dcf-26c31adbb0bb","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# RDD のパーティション数を返します\ndf.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee48ce05-b898-4a9a-8a2a-4b876292e202","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## キャッシュ\nPyspark の `cache()` メソッドを使用して変換の中間結果をキャッシュし、キャッシュされた上で実行される他の変換がより高速に実行されるようにします。変換の結果をキャッシュすることは、長時間実行される PySpark アプリケーション/ジョブのパフォーマンスを向上させるための最適化のトリックの 1 つです。\n\nhttps://sparkbyexamples.com/pyspark/pyspark-cache-explained/"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d281cab6-e6da-4038-baf9-3f21252ba09f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"222a9071-5abc-43ff-acab-02b8889fa3e3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ユーザー定義関数 (UDF) \nユーザー定義関数 (UDF) は、ユーザーによって定義された関数であり、ユーザー環境でカスタム ロジックを再利用できます。Databricks は、拡張可能なロジックを配布できるように、さまざまな種類の UDF をサポートしています。<br><br>\n\n- https://docs.databricks.com/udf/index.html\n- https://docs.databricks.com/udf/python.html#use-udf-with-dataframes"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fe97d9e7-2b5e-4172-8b75-4bb3eb53024f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Polygon 座標から面積を計算する UDF を定義\n\nGeoJson から得られる Polygon 座標を投影座標に変換した後、m^2 の単位で面積を計算します。"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"94d1dc4b-33f9-4571-8aad-1ed05ae2b84e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType, DecimalType\nfrom pyspark.sql.functions import lit, pandas_udf, PandasUDFType, col\nfrom shapely.geometry import Polygon, shape\nimport geopandas as gpd\nimport pyproj\nfrom shapely.ops import transform\n\nwgs84 = pyproj.CRS('EPSG:4326')\nutm = pyproj.CRS('EPSG:3100')\nproject = pyproj.Transformer.from_crs(wgs84, utm, always_xy=True).transform\n\ndef calc_area(geometry): \n    polygon_geom = shape(geometry.asDict(True))\n    utm_point = transform(project, polygon_geom)\n    area = str(utm_point.area)\n  \n    return area\n\ncalc_area_udf = udf(calc_area, StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"050b4a13-015f-47e7-abe1-c60fb80d8dac","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 列を追加する\nPySpark `withColumn()` は、値の変更、既存の列のデータ型の変換、新しい列の作成などに使用される DataFrame の変換関数です。\n\nhttps://sparkbyexamples.com/pyspark/pyspark-withcolumn/"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"028cbc24-3283-4b34-80a0-0cceeadc2cc0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%%time\n\n# area 列を追加\njoined = df.withColumn(\"area\", calc_area_udf(col(\"geometry\")))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e25ccb49-d415-474e-bd8e-d90e471cd54e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## ファイルに保存\nSpark の遅延評価のため、下記の保存を実行するまで実際の演算は実行されません。"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f353bea2-7fa3-46c8-a6af-a3d68b36345e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%%time\njoined.write.mode('Overwrite').json(\"/mnt/testblob/geojson/sparkarea\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"185773e3-7245-48ad-a467-846f323a646c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## 参考　GeoPandas による非並列ロード\n\nSpark を使わずに GeoPandas の機能を使って面積を計算する処理を実装します。<br>\n注意：読み込みには約 4 分程度かかります。"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f50b7535-4ede-4216-a50e-a6cdfc92dca1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from geopandas import GeoDataFrame\n\n# Loading cropfields Data\ngeo_df = GeoDataFrame.from_file('/dbfs/mnt/testblob/geojson/niigata_cropfiled_geojsonl.json')\ngeo_df.head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2716a41-25e6-4479-a213-741a7f4b46ac","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# CRS の確認\ngeo_df.crs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c855a13-f580-4062-9713-75a25e9118b0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# CRS の変換\ngeo_df = geo_df.to_crs(epsg=3100)\ngeo_df.head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e2c7c6d5-a00b-4ec4-846e-1e5ee049fdda","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# GeoPandas の面積計算(m^2)\ngeo_df[\"area\"] = geo_df['geometry'].area\ngeo_df.head(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70a21091-a5e9-4f48-b75a-06de7ca1e227","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["注意：保存には約 12 分程度かかります。"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c22246fb-2c03-423f-8ae7-bfe2e8be1923","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%%time\ngeo_df.to_file(\"/dbfs/mnt/testblob/geojson/niigata_area.json\", driver='GeoJSONSeq')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e86426d5-82a9-4577-8e2e-8026a9421052","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Geo_Exercise2_Vector_Processing","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4051799740321312}},"nbformat":4,"nbformat_minor":0}
